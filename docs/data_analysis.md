# 데이터 분석

## 1. 데이터 전처리 프로세스 개요

1. **노이즈 데이터 정제 (Pruning Noisy Data)**
2. **노이즈 추정 계산 (Counting to Estimate Noise)**
3. **학습을 위한 예제 순위 매기기 (Ranking Examples to Train with Confidence)**

## 2. 데이터 개요

- **정상 데이터**: 200개
- **라벨링 에러 데이터**: 1000개 (잘못된 라벨링이 되어 있어 올바르게 재맵핑 필요)
- **랜덤 노이즈 데이터**: 1600개 (텍스트 내 20-80%의 문자가 랜덤 아스키 코드로 대체됨)

## 3. 데이터 분류 작업 및 기준

- **노이즈 데이터 필터링**: 심각한 노이즈가 포함된 데이터를 자동으로 필터링하거나 수정
- **노이즈 데이터 복구**: 의미가 유지될 정도로 노이즈가 적은 데이터를 자동 복구
- **라벨링 에러 수정**: 잘못된 라벨을 자동으로 재맵핑

### 판단 기준
- **심각한 노이즈**: 데이터 복구가 불가능해 제거해야 하는 수준의 노이즈
- **복구 가능한 노이즈**: 의미를 유지할 수 있는 수준의 노이즈, 복구 후 유지 
- **잘못된 라벨**: 명백히 잘못된 라벨링을 식별하여 수정 필요

## 4. 데이터 분류 및 처리 담당자

노션 페이지(DATA EDA) 생성자 기준으로 정리함
- **서재덕**: *TODO 각자 내용 채우기*
- **유채은**: *TODO 각자 내용 채우기*
- **이서현**: *TODO 각자 내용 채우기*

## 5. 추가 분석 사항
- **생활문화와 사회**: 두 라벨 간 구분이 모호하므로 추가적인 EDA 필요
- **노이즈 데이터 처리**: 사람이 개별 판단하지 않고, 자동 탐지 및 수정 방식 사용
- **라벨링 에러**: Cleanlab을 활용해 자동으로 에러 탐지 및 수정 진행

## 7. 참고 문헌
- *TODO 참고 문헌 채워 넣기*